{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30413e2",
   "metadata": {},
   "source": [
    "# Parviflo — LIVE Data Notebook (OBIS + ERDDAP)\n",
    "\n",
    "Pulls **real** jellyfish occurrences (OBIS) and **real** satellite/environment layers (ERDDAP).\n",
    "All visuals are produced here with Matplotlib/Cartopy (no separate front-end)."
   ]
  },
  {
   "cell_type": "code",
   "id": "c200a339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T04:03:45.894920Z",
     "start_time": "2025-10-01T04:03:45.540561Z"
    }
   },
   "source": [
    "import os, warnings\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Cartopy is optional; maps will fall back to plain imshow if not installed\n",
    "try:\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    HAS_CARTOPY = True\n",
    "except Exception:\n",
    "    HAS_CARTOPY = False\n",
    "\n",
    "# Region and grid\n",
    "BBOX = (-6.0, 30.0, 36.0, 46.0)  # min_lon, min_lat, max_lon, max_lat (Mediterranean)\n",
    "GRID_DEG = 0.25\n",
    "\n",
    "# Time window: last 12 full months\n",
    "END = (pd.Timestamp.utcnow() - pd.offsets.MonthEnd(1)).normalize()\n",
    "START = END - pd.DateOffset(months=11)\n",
    "MONTHS = pd.period_range(START.to_period('M'), END.to_period('M'), freq='M')\n",
    "\n",
    "print('BBOX:', BBOX)\n",
    "print('Months:', MONTHS[0], 'to', MONTHS[-1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBOX: (-6.0, 30.0, 36.0, 46.0)\n",
      "Months: 2024-10 to 2025-09\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "0ef2e892",
   "metadata": {},
   "source": [
    "## 1) OBIS — Jellyfish occurrences (Scyphozoa)\n",
    "\n",
    "We query the OBIS v3 API within the bbox and aggregate per 0.25° cell per month."
   ]
  },
  {
   "cell_type": "code",
   "id": "b57d189c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-01T04:03:45.968988Z"
    }
   },
   "source": [
    "OBIS_BASE = 'https://api.obis.org/v3/occurrence'\n",
    "\n",
    "def obis_monthly_counts(bbox: Tuple[float,float,float,float], year:int, month:int, taxon_class='Scyphozoa', page_size=2000):\n",
    "    \"\"\"Return DataFrame [lat_bin, lon_bin, jelly_n] for (year, month) from OBIS.\"\"\"\n",
    "    poly = f\"POLYGON(({bbox[0]} {bbox[1]},{bbox[2]} {bbox[1]},{bbox[2]} {bbox[3]},{bbox[0]} {bbox[3]},{bbox[0]} {bbox[1]}))\"\n",
    "    start = pd.Timestamp(year=year, month=month, day=1)\n",
    "    end = (start + pd.offsets.MonthEnd(1)).date().isoformat()\n",
    "\n",
    "    offset = 0\n",
    "    recs = []\n",
    "    while True:\n",
    "        params = dict(\n",
    "            geometry=poly,\n",
    "            startdate=start.date().isoformat(),\n",
    "            enddate=end,\n",
    "            Class=taxon_class,\n",
    "            size=page_size,\n",
    "            _from=offset\n",
    "        )\n",
    "        r = requests.get(OBIS_BASE, params=params, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        data = r.json().get('results', [])\n",
    "        if not data:\n",
    "            break\n",
    "        recs.extend(data)\n",
    "        if len(data) < page_size:\n",
    "            break\n",
    "        offset += page_size\n",
    "\n",
    "    if not recs:\n",
    "        return pd.DataFrame(columns=['lat_bin','lon_bin','jelly_n'])\n",
    "\n",
    "    df = pd.DataFrame(recs)\n",
    "    df = df.dropna(subset=['decimalLatitude','decimalLongitude'])\n",
    "    df['lat_bin'] = np.floor(df['decimalLatitude']/GRID_DEG)*GRID_DEG\n",
    "    df['lon_bin'] = np.floor(df['decimalLongitude']/GRID_DEG)*GRID_DEG\n",
    "    out = df.groupby(['lat_bin','lon_bin']).size().reset_index(name='jelly_n')\n",
    "    return out\n",
    "\n",
    "# Pull last 12 months\n",
    "jelly_monthly = []\n",
    "for p in MONTHS:\n",
    "    y, m = p.year, p.month\n",
    "    print(f'OBIS {y}-{m:02d}...')\n",
    "    try:\n",
    "        c = obis_monthly_counts(BBOX, y, m)\n",
    "        c['year'] = y; c['month'] = m\n",
    "        jelly_monthly.append(c)\n",
    "    except Exception as e:\n",
    "        print('  OBIS error:', e)\n",
    "\n",
    "jelly_df = pd.concat(jelly_monthly, ignore_index=True) if jelly_monthly else pd.DataFrame(columns=['lat_bin','lon_bin','jelly_n','year','month'])\n",
    "jelly_df.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBIS 2024-10...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81f19fa2",
   "metadata": {},
   "source": [
    "## 2) ERDDAP — Chlorophyll & SST\n",
    "\n",
    "- Chlorophyll (OLCI global 4km): `noaacwS3AOLCIchlaDaily`\n",
    "- SST (OISST 0.25°): `ncdc_oisst_v2_avhrr_by_time_zlev_lat_lon`\n",
    "\n",
    "We convert daily data to monthly means and subset to the bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ERDDAP_CHLA = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwS3AOLCIchlaDaily.nc'\n",
    "ERDDAP_OISST = 'https://www.ncei.noaa.gov/erddap/griddap/ncdc_oisst_v2_avhrr_by_time_zlev_lat_lon.nc'\n",
    "\n",
    "def monthly_field(ds_url: str, start: str, end: str, bbox: Tuple[float,float,float,float]):\n",
    "    ds = xr.open_dataset(ds_url)\n",
    "    # coord names\n",
    "    lat_name = 'latitude' if 'latitude' in ds.coords else 'lat'\n",
    "    lon_name = 'longitude' if 'longitude' in ds.coords else 'lon'\n",
    "    tname = 'time'\n",
    "    sub = ds.sel({tname: slice(start, end)})\n",
    "    lmin, lmax = bbox[0], bbox[2]\n",
    "    if float(sub[lon_name].max()) > 180:\n",
    "        lmin = (lmin + 360) % 360\n",
    "        lmax = (lmax + 360) % 360\n",
    "    sub = sub.sel({lat_name: slice(bbox[1], bbox[3]), lon_name: slice(lmin, lmax)})\n",
    "    var = list(sub.data_vars)[0]\n",
    "    return sub[var].resample({tname: '1MS'}).mean()\n",
    "\n",
    "chla_m = monthly_field(ERDDAP_CHLA, str(MONTHS[0].start_time.date()), str(MONTHS[-1].end_time.date()), BBOX)\n",
    "sst_m  = monthly_field(ERDDAP_OISST, str(MONTHS[0].start_time.date()), str(MONTHS[-1].end_time.date()), BBOX)\n",
    "\n",
    "chla_m, sst_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ecbbc7",
   "metadata": {},
   "source": [
    "## 3) Features, labels, and model (logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978349c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# Grid cells\n",
    "lats = np.arange(BBOX[1], BBOX[3]+1e-9, GRID_DEG)\n",
    "lons = np.arange(BBOX[0], BBOX[2]+1e-9, GRID_DEG)\n",
    "cells = pd.MultiIndex.from_product([np.round(lats,6), np.round(lons,6)], names=['lat_bin','lon_bin']).to_frame(index=False)\n",
    "\n",
    "# months table\n",
    "T = pd.DataFrame([(p.year, p.month) for p in MONTHS], columns=['year','month'])\n",
    "mesh = cells.merge(T, how='cross')\n",
    "\n",
    "# JellyIdx\n",
    "j = jelly_df.copy()\n",
    "j['JellyIdx'] = np.log1p(j['jelly_n'])\n",
    "mesh = mesh.merge(j[['lat_bin','lon_bin','year','month','JellyIdx']], on=['lat_bin','lon_bin','year','month'], how='left')\n",
    "mesh['JellyIdx'] = mesh['JellyIdx'].fillna(0.0)\n",
    "\n",
    "# Convert DataArrays to tables\n",
    "def da_to_df(da, name):\n",
    "    df = da.to_dataframe(name=name).reset_index()\n",
    "    lat_name = 'latitude' if 'latitude' in df.columns else 'lat'\n",
    "    lon_name = 'longitude' if 'longitude' in df.columns else 'lon'\n",
    "    df['year'] = pd.to_datetime(df['time']).dt.year\n",
    "    df['month'] = pd.to_datetime(df['time']).dt.month\n",
    "    df = df.rename(columns={lat_name: 'lat_bin', lon_name: 'lon_bin'})\n",
    "    return df[['lat_bin','lon_bin','year','month', name]]\n",
    "\n",
    "mesh = mesh.merge(da_to_df(chla_m, 'chla'), on=['lat_bin','lon_bin','year','month'], how='left')\n",
    "mesh = mesh.merge(da_to_df(sst_m, 'sst'),  on=['lat_bin','lon_bin','year','month'], how='left')\n",
    "\n",
    "# Simple climatology = first 3 months per cell\n",
    "def anomaly_by_cell(df, col, k=3):\n",
    "    base = df.groupby(['lat_bin','lon_bin'])[col].apply(lambda s: s.iloc[:k].mean()).reset_index().rename(columns={col: f'{col}_clim'})\n",
    "    out = df.merge(base, on=['lat_bin','lon_bin'], how='left')\n",
    "    out[f'{col}_anom'] = out[col] - out[f'{col}_clim']\n",
    "    return out\n",
    "\n",
    "mesh = anomaly_by_cell(mesh, 'sst')\n",
    "mesh = anomaly_by_cell(mesh, 'chla')\n",
    "\n",
    "mesh = mesh.sort_values(['lat_bin','lon_bin','year','month']).reset_index(drop=True)\n",
    "mesh['flip_now'] = (mesh['JellyIdx'] > mesh.groupby(['lat_bin','lon_bin'])['JellyIdx'].transform(lambda s: s.quantile(0.7))).astype(int)\n",
    "\n",
    "def make_samples(df, lags=6, fmin=3, fmax=6):\n",
    "    rows = []\n",
    "    for (la,lo), g in df.groupby(['lat_bin','lon_bin']):\n",
    "        g = g.reset_index(drop=True)\n",
    "        for i in range(lags, len(g)-fmax):\n",
    "            past = g.iloc[i-lags:i]\n",
    "            fut  = g.iloc[i+fmin:i+fmax+1]\n",
    "            feat = {\n",
    "                'lat_bin': la, 'lon_bin': lo,\n",
    "                'JellyIdx_last': past['JellyIdx'].iloc[-1],\n",
    "                'JellyIdx_mean': past['JellyIdx'].mean(),\n",
    "                'sst_anom_last': past['sst_anom'].iloc[-1],\n",
    "                'sst_anom_mean': past['sst_anom'].mean(),\n",
    "                'chla_anom_last': past['chla_anom'].iloc[-1],\n",
    "                'chla_anom_mean': past['chla_anom'].mean(),\n",
    "            }\n",
    "            y = 1 if fut['flip_now'].mean() >= 0.5 else 0\n",
    "            feat['y'] = y\n",
    "            rows.append(feat)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "samples = make_samples(mesh, lags=6, fmin=3, fmax=6)\n",
    "FEATURES = [c for c in samples.columns if c not in ['lat_bin','lon_bin','y']]\n",
    "X = samples[FEATURES].values\n",
    "y = samples['y'].values\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "clf = LogisticRegression(max_iter=400, class_weight='balanced').fit(Xtr, ytr)\n",
    "probs = clf.predict_proba(Xte)[:,1]\n",
    "print('AUC:', roc_auc_score(yte, probs).round(3), 'Brier:', brier_score_loss(yte, probs).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35489150",
   "metadata": {},
   "source": [
    "## 4) Flip-Risk Map (live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78524bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_latest_map(df, clf, features: List[str]):\n",
    "    rows = []\n",
    "    for (la,lo), g in df.groupby(['lat_bin','lon_bin']):\n",
    "        g = g.sort_values(['year','month'])\n",
    "        g_last = g.tail(6)\n",
    "        if len(g_last) < 6: \n",
    "            continue\n",
    "        feat = {\n",
    "            'JellyIdx_last': g_last['JellyIdx'].iloc[-1],\n",
    "            'JellyIdx_mean': g_last['JellyIdx'].mean(),\n",
    "            'sst_anom_last': g_last['sst_anom'].iloc[-1],\n",
    "            'sst_anom_mean': g_last['sst_anom'].mean(),\n",
    "            'chla_anom_last': g_last['chla_anom'].iloc[-1],\n",
    "            'chla_anom_mean': g_last['chla_anom'].mean(),\n",
    "        }\n",
    "        Xv = np.array([feat[f] for f in features]).reshape(1,-1)\n",
    "        p = clf.predict_proba(Xv)[:,1][0]\n",
    "        rows.append({'lat': la, 'lon': lo, 'flip_risk': float(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "flipmap = predict_latest_map(mesh, clf, FEATURES)\n",
    "\n",
    "def plot_map(df, title='Flip-Risk (next 6 months)'):\n",
    "    pivot = df.pivot_table(index='lat', columns='lon', values='flip_risk', aggfunc='mean').sort_index()\n",
    "    plt.figure(figsize=(9,6))\n",
    "    if HAS_CARTOPY:\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([BBOX[0], BBOX[2], BBOX[1], BBOX[3]], crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.LAND, edgecolor='black', linewidth=0.4, zorder=2)\n",
    "        im = ax.imshow(pivot.values, origin='lower',\n",
    "                       extent=[pivot.columns.min(), pivot.columns.max(), pivot.index.min(), pivot.index.max()],\n",
    "                       vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
    "        plt.colorbar(im, ax=ax, label='Flip-Risk (0..1)')\n",
    "        ax.set_title(title)\n",
    "    else:\n",
    "        im = plt.imshow(pivot.values, origin='lower',\n",
    "                        extent=[pivot.columns.min(), pivot.columns.max(), pivot.index.min(), pivot.index.max()],\n",
    "                        vmin=0, vmax=1, aspect='auto')\n",
    "        plt.colorbar(im, label='Flip-Risk (0..1)')\n",
    "        plt.title(title); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_map(flipmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239383f",
   "metadata": {},
   "source": [
    "## 5) Hotspot Watch-List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239666bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import theilslopes\n",
    "\n",
    "def monthly_risk_series(df_grid, clf, features):\n",
    "    rows = []\n",
    "    for p in MONTHS:\n",
    "        ym = (df_grid['year']<p.year) | ((df_grid['year']==p.year) & (df_grid['month']<=p.month))\n",
    "        g2 = df_grid[ym]\n",
    "        pred = predict_latest_map(g2, clf, features)\n",
    "        pred['time'] = p.to_timestamp(how='end')\n",
    "        rows.append(pred)\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "risk_series = monthly_risk_series(mesh, clf, FEATURES)\n",
    "\n",
    "def make_demo_zones(bbox=BBOX):\n",
    "    lon_splits = np.linspace(bbox[0], bbox[2], 4)\n",
    "    lat_splits = np.linspace(bbox[1], bbox[3], 3)\n",
    "    zones = []\n",
    "    zid = 1\n",
    "    for i in range(len(lat_splits)-1):\n",
    "        for j in range(len(lon_splits)-1):\n",
    "            zones.append({\n",
    "                'zone_id': f'Z{zid}',\n",
    "                'lat_min': float(lat_splits[i]), 'lat_max': float(lat_splits[i+1]),\n",
    "                'lon_min': float(lon_splits[j]), 'lon_max': float(lon_splits[j+1])\n",
    "            })\n",
    "            zid += 1\n",
    "    return pd.DataFrame(zones)\n",
    "\n",
    "zones = make_demo_zones()\n",
    "\n",
    "def zone_watchlist(risk_series, zones):\n",
    "    rows = []\n",
    "    for _, z in zones.iterrows():\n",
    "        sel = risk_series[(risk_series['lat']>=z.lat_min)&(risk_series['lat']<z.lat_max)&\n",
    "                          (risk_series['lon']>=z.lon_min)&(risk_series['lon']<z.lon_max)]\n",
    "        if sel.empty: \n",
    "            continue\n",
    "        g = sel.groupby('time')['flip_risk'].mean().reset_index()\n",
    "        if len(g) >= 3:\n",
    "            x = (g['time'] - g['time'].min()).dt.days.values/30.0\n",
    "            slope, intercept, _, _ = theilslopes(g['flip_risk'].values, x)\n",
    "        else:\n",
    "            slope, intercept = np.nan, np.nan\n",
    "        rows.append({'zone_id': z.zone_id, 'mean_risk': g['flip_risk'].mean(), 'trend': slope})\n",
    "    out = pd.DataFrame(rows)\n",
    "    out['rank'] = out.sort_values(['trend','mean_risk'], ascending=[False,False]).reset_index(drop=True).index+1\n",
    "    return out.sort_values('rank')\n",
    "\n",
    "watchlist = zone_watchlist(risk_series, zones)\n",
    "watchlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e2f46",
   "metadata": {},
   "source": [
    "## 6) (Optional) ICES fish index\n",
    "\n",
    "Add ICES assessment tables by providing `AssessmentKey` values; map to your grid or zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "ICES_SVC = 'https://stock-assessment-graphs.ices.dk/services/odata'\n",
    "\n",
    "def ices_get_stock_download(assessment_key: int) -> pd.DataFrame:\n",
    "    url = f'{ICES_SVC}/GetStockDownloadData(AssessmentKey={assessment_key})'\n",
    "    return pd.read_json(url)\n",
    "\n",
    "ASSESSMENT_KEYS = []  # e.g., [1802, 1786]\n",
    "ices_tables = []\n",
    "for k in ASSESSMENT_KEYS:\n",
    "    try:\n",
    "        dfk = ices_get_stock_download(k)\n",
    "        dfk['AssessmentKey'] = k\n",
    "        ices_tables.append(dfk)\n",
    "    except Exception as e:\n",
    "        print('ICES error for', k, ':', e)\n",
    "\n",
    "if ices_tables:\n",
    "    ices_df = pd.concat(ices_tables, ignore_index=True)\n",
    "    display(ices_df.head())\n",
    "else:\n",
    "    print('Add keys to ASSESSMENT_KEYS to fetch ICES tables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34116880",
   "metadata": {},
   "source": [
    "## 7) Save artifacts for slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path('outputs_parviflo_live').mkdir(parents=True, exist_ok=True)\n",
    "flipmap.to_csv('outputs_parviflo_live/fliprisk_grid.csv', index=False)\n",
    "watchlist.to_csv('outputs_parviflo_live/hotspot_watchlist.csv', index=False)\n",
    "\n",
    "# Save map image\n",
    "plot_map(flipmap, title='Flip-Risk (Live, next 6 months)')\n",
    "plt.savefig('outputs_parviflo_live/fliprisk_map.png', dpi=160, bbox_inches='tight')\n",
    "print('Saved files in outputs_parviflo_live/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
